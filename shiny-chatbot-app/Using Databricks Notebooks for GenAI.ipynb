{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7eaf2a62-6204-4128-84d5-7cf8fb0b96c5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from mlflow.deployments import get_deploy_client\n",
    "from databricks.sdk import WorkspaceClient\n",
    "\n",
    "def _get_endpoint_task_type(endpoint_name: str) -> str:\n",
    "    \"\"\"Get the task type of a serving endpoint.\"\"\"\n",
    "    w = WorkspaceClient()\n",
    "    ep = w.serving_endpoints.get(endpoint_name)\n",
    "    return ep.task\n",
    "\n",
    "def is_endpoint_supported(endpoint_name: str) -> bool:\n",
    "    \"\"\"Check if the endpoint has a supported task type.\"\"\"\n",
    "    task_type = _get_endpoint_task_type(endpoint_name)\n",
    "    supported_task_types = [\"agent/v1/chat\", \"agent/v2/chat\", \"llm/v1/chat\"]\n",
    "    return task_type in supported_task_types\n",
    "\n",
    "def _validate_endpoint_task_type(endpoint_name: str) -> None:\n",
    "    \"\"\"Validate that the endpoint has a supported task type.\"\"\"\n",
    "    if not is_endpoint_supported(endpoint_name):\n",
    "        raise Exception(\n",
    "            f\"Detected unsupported endpoint type for this basic chatbot template. \"\n",
    "            f\"This chatbot template only supports chat completions-compatible endpoints. \"\n",
    "            f\"For a richer chatbot template with support for all conversational endpoints on Databricks, \"\n",
    "            f\"see https://docs.databricks.com/aws/en/generative-ai/agent-framework/chat-app\"\n",
    "        )\n",
    "\n",
    "def _query_endpoint(endpoint_name: str, messages: list[dict[str, str]], max_tokens) -> list[dict[str, str]]:\n",
    "    \"\"\"Calls a model serving endpoint.\"\"\"\n",
    "    _validate_endpoint_task_type(endpoint_name)\n",
    "    \n",
    "    res = get_deploy_client('databricks').predict(\n",
    "        endpoint=endpoint_name,\n",
    "        inputs={'messages': messages, \"max_tokens\": max_tokens},\n",
    "    )\n",
    "    if \"messages\" in res:\n",
    "        return res[\"messages\"]\n",
    "    elif \"choices\" in res:\n",
    "        choice_message = res[\"choices\"][0][\"message\"]\n",
    "        choice_content = choice_message.get(\"content\")\n",
    "        \n",
    "        # Case 1: The content is a list of structured objects\n",
    "        if isinstance(choice_content, list):\n",
    "            combined_content = \"\".join([part.get(\"text\", \"\") for part in choice_content if part.get(\"type\") == \"text\"])\n",
    "            reformatted_message = {\n",
    "                \"role\": choice_message.get(\"role\"),\n",
    "                \"content\": combined_content\n",
    "            }\n",
    "            return [reformatted_message]\n",
    "        \n",
    "        # Case 2: The content is a simple string\n",
    "        elif isinstance(choice_content, str):\n",
    "            return [choice_message]\n",
    "    raise Exception(\"This app can only run against:\"\n",
    "                    \"1) Databricks foundation model or external model endpoints with the chat task type (described in https://docs.databricks.com/aws/en/machine-learning/model-serving/score-foundation-models#chat-completion-model-query)\"\n",
    "                    \"2) Databricks agent serving endpoints that implement the conversational agent schema documented \"\n",
    "                    \"in https://docs.databricks.com/aws/en/generative-ai/agent-framework/author-agent\")\n",
    "\n",
    "def query_endpoint(endpoint_name, messages, max_tokens):\n",
    "    \"\"\"\n",
    "    Query a chat-completions or agent serving endpoint\n",
    "    If querying an agent serving endpoint that returns multiple messages, this method\n",
    "    returns the last message\n",
    "    .\"\"\"\n",
    "    return _query_endpoint(endpoint_name, messages, max_tokens)[-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "22d83bb3-f18c-44f3-9d6f-5b5220d226a4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n  {\n    \"role\": \"assistant\",\n    \"content\": \"The capital of Japan is **Tokyo**.\"\n  }\n]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import json\n",
    "from mlflow.deployments import get_deploy_client\n",
    "from databricks.sdk import WorkspaceClient\n",
    "\n",
    "endpoint_name = \"databricks-gpt-oss-120b\" # any model from \"Serving\" left menu\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"You are a helpful assistant.\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"What is the capital of Japan?\"\n",
    "    }\n",
    "]\n",
    "max_tokens = 400\n",
    "\n",
    "def query_endpoint(endpoint_name: str, messages: list[dict[str, str]], max_tokens) -> list[dict[str, str]]:\n",
    "    \"\"\"Calls a model serving endpoint.\"\"\"\n",
    "   \n",
    "    res = get_deploy_client('databricks').predict(\n",
    "        endpoint=endpoint_name,\n",
    "        inputs={'messages': messages, \"max_tokens\": max_tokens},\n",
    "    )\n",
    "    if \"messages\" in res:\n",
    "        return res[\"messages\"]\n",
    "    elif \"choices\" in res:\n",
    "        choice_message = res[\"choices\"][0][\"message\"]\n",
    "        choice_content = choice_message.get(\"content\")\n",
    "        \n",
    "        # Case 1: The content is a list of structured objects\n",
    "        if isinstance(choice_content, list):\n",
    "            combined_content = \"\".join([part.get(\"text\", \"\") for part in choice_content if part.get(\"type\") == \"text\"])\n",
    "            reformatted_message = {\n",
    "                \"role\": choice_message.get(\"role\"),\n",
    "                \"content\": combined_content\n",
    "            }\n",
    "            return [reformatted_message]\n",
    "        \n",
    "        # Case 2: The content is a simple string\n",
    "        elif isinstance(choice_content, str):\n",
    "            return [choice_message]\n",
    "    raise Exception(\"This app can only run against:\"\n",
    "                    \"1) Databricks foundation model or external model endpoints with the chat task type (described in https://docs.databricks.com/aws/en/machine-learning/model-serving/score-foundation-models#chat-completion-model-query)\"\n",
    "                    \"2) Databricks agent serving endpoints that implement the conversational agent schema documented \"\n",
    "                    \"in https://docs.databricks.com/aws/en/generative-ai/agent-framework/author-agent\")\n",
    "\n",
    "res = query_endpoint(endpoint_name, messages, max_tokens)\n",
    "print(json.dumps(res, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e0d0a9e9-5f8f-487c-aff4-1086662c8a33",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: databricks-sdk>=0.35.0 in /databricks/python3/lib/python3.12/site-packages (from databricks-sdk[openai]>=0.35.0) (0.49.0)\nRequirement already satisfied: requests<3,>=2.28.1 in /databricks/python3/lib/python3.12/site-packages (from databricks-sdk>=0.35.0->databricks-sdk[openai]>=0.35.0) (2.32.3)\nRequirement already satisfied: google-auth~=2.0 in /databricks/python3/lib/python3.12/site-packages (from databricks-sdk>=0.35.0->databricks-sdk[openai]>=0.35.0) (2.40.0)\nCollecting openai (from databricks-sdk[openai]>=0.35.0)\n  Downloading openai-2.8.1-py3-none-any.whl.metadata (29 kB)\nCollecting langchain-openai (from databricks-sdk[openai]>=0.35.0)\n  Downloading langchain_openai-1.0.3-py3-none-any.whl.metadata (2.6 kB)\nRequirement already satisfied: httpx in /databricks/python3/lib/python3.12/site-packages (from databricks-sdk[openai]>=0.35.0) (0.27.0)\nRequirement already satisfied: cachetools<6.0,>=2.0.0 in /databricks/python3/lib/python3.12/site-packages (from google-auth~=2.0->databricks-sdk>=0.35.0->databricks-sdk[openai]>=0.35.0) (5.5.1)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /databricks/python3/lib/python3.12/site-packages (from google-auth~=2.0->databricks-sdk>=0.35.0->databricks-sdk[openai]>=0.35.0) (0.2.8)\nRequirement already satisfied: rsa<5,>=3.1.4 in /databricks/python3/lib/python3.12/site-packages (from google-auth~=2.0->databricks-sdk>=0.35.0->databricks-sdk[openai]>=0.35.0) (4.9.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /databricks/python3/lib/python3.12/site-packages (from requests<3,>=2.28.1->databricks-sdk>=0.35.0->databricks-sdk[openai]>=0.35.0) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /databricks/python3/lib/python3.12/site-packages (from requests<3,>=2.28.1->databricks-sdk>=0.35.0->databricks-sdk[openai]>=0.35.0) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /databricks/python3/lib/python3.12/site-packages (from requests<3,>=2.28.1->databricks-sdk>=0.35.0->databricks-sdk[openai]>=0.35.0) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /databricks/python3/lib/python3.12/site-packages (from requests<3,>=2.28.1->databricks-sdk>=0.35.0->databricks-sdk[openai]>=0.35.0) (2025.1.31)\nRequirement already satisfied: anyio in /databricks/python3/lib/python3.12/site-packages (from httpx->databricks-sdk[openai]>=0.35.0) (4.6.2)\nRequirement already satisfied: httpcore==1.* in /databricks/python3/lib/python3.12/site-packages (from httpx->databricks-sdk[openai]>=0.35.0) (1.0.2)\nRequirement already satisfied: sniffio in /databricks/python3/lib/python3.12/site-packages (from httpx->databricks-sdk[openai]>=0.35.0) (1.3.0)\nRequirement already satisfied: h11<0.15,>=0.13 in /databricks/python3/lib/python3.12/site-packages (from httpcore==1.*->httpx->databricks-sdk[openai]>=0.35.0) (0.14.0)\nCollecting langchain-core<2.0.0,>=1.0.2 (from langchain-openai->databricks-sdk[openai]>=0.35.0)\n  Downloading langchain_core-1.0.5-py3-none-any.whl.metadata (3.6 kB)\nCollecting tiktoken<1.0.0,>=0.7.0 (from langchain-openai->databricks-sdk[openai]>=0.35.0)\n  Downloading tiktoken-0.12.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (6.7 kB)\nRequirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai->databricks-sdk[openai]>=0.35.0) (1.9.0)\nCollecting jiter<1,>=0.10.0 (from openai->databricks-sdk[openai]>=0.35.0)\n  Downloading jiter-0.12.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.2 kB)\nRequirement already satisfied: pydantic<3,>=1.9.0 in /databricks/python3/lib/python3.12/site-packages (from openai->databricks-sdk[openai]>=0.35.0) (2.10.6)\nCollecting tqdm>4 (from openai->databricks-sdk[openai]>=0.35.0)\n  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\nRequirement already satisfied: typing-extensions<5,>=4.11 in /databricks/python3/lib/python3.12/site-packages (from openai->databricks-sdk[openai]>=0.35.0) (4.12.2)\nCollecting jsonpatch<2.0.0,>=1.33.0 (from langchain-core<2.0.0,>=1.0.2->langchain-openai->databricks-sdk[openai]>=0.35.0)\n  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\nCollecting langsmith<1.0.0,>=0.3.45 (from langchain-core<2.0.0,>=1.0.2->langchain-openai->databricks-sdk[openai]>=0.35.0)\n  Downloading langsmith-0.4.43-py3-none-any.whl.metadata (14 kB)\nRequirement already satisfied: packaging<26.0.0,>=23.2.0 in /databricks/python3/lib/python3.12/site-packages (from langchain-core<2.0.0,>=1.0.2->langchain-openai->databricks-sdk[openai]>=0.35.0) (24.1)\nRequirement already satisfied: pyyaml<7.0.0,>=5.3.0 in /databricks/python3/lib/python3.12/site-packages (from langchain-core<2.0.0,>=1.0.2->langchain-openai->databricks-sdk[openai]>=0.35.0) (6.0.2)\nRequirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /databricks/python3/lib/python3.12/site-packages (from langchain-core<2.0.0,>=1.0.2->langchain-openai->databricks-sdk[openai]>=0.35.0) (9.0.0)\nRequirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /databricks/python3/lib/python3.12/site-packages (from pyasn1-modules>=0.2.1->google-auth~=2.0->databricks-sdk>=0.35.0->databricks-sdk[openai]>=0.35.0) (0.4.8)\nRequirement already satisfied: annotated-types>=0.6.0 in /databricks/python3/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai->databricks-sdk[openai]>=0.35.0) (0.7.0)\nRequirement already satisfied: pydantic-core==2.27.2 in /databricks/python3/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai->databricks-sdk[openai]>=0.35.0) (2.27.2)\nCollecting regex>=2022.1.18 (from tiktoken<1.0.0,>=0.7.0->langchain-openai->databricks-sdk[openai]>=0.35.0)\n  Downloading regex-2025.11.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (40 kB)\nRequirement already satisfied: jsonpointer>=1.9 in /databricks/python3/lib/python3.12/site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.0.2->langchain-openai->databricks-sdk[openai]>=0.35.0) (3.0.0)\nCollecting orjson>=3.9.14 (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.2->langchain-openai->databricks-sdk[openai]>=0.35.0)\n  Downloading orjson-3.11.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (41 kB)\nCollecting requests-toolbelt>=1.0.0 (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.2->langchain-openai->databricks-sdk[openai]>=0.35.0)\n  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\nRequirement already satisfied: zstandard>=0.23.0 in /databricks/python3/lib/python3.12/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.2->langchain-openai->databricks-sdk[openai]>=0.35.0) (0.23.0)\nDownloading langchain_openai-1.0.3-py3-none-any.whl (82 kB)\nDownloading openai-2.8.1-py3-none-any.whl (1.0 MB)\n\u001B[?25l   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m0.0/1.0 MB\u001B[0m \u001B[31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\r\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m1.0/1.0 MB\u001B[0m \u001B[31m34.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n\u001B[?25hDownloading jiter-0.12.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (361 kB)\nDownloading langchain_core-1.0.5-py3-none-any.whl (471 kB)\nDownloading tiktoken-0.12.0-cp312-cp312-manylinux_2_28_x86_64.whl (1.2 MB)\n\u001B[?25l   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m0.0/1.2 MB\u001B[0m \u001B[31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\r\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m1.2/1.2 MB\u001B[0m \u001B[31m61.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n\u001B[?25hDownloading tqdm-4.67.1-py3-none-any.whl (78 kB)\nDownloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\nDownloading langsmith-0.4.43-py3-none-any.whl (410 kB)\nDownloading regex-2025.11.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (803 kB)\n\u001B[?25l   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m0.0/803.5 kB\u001B[0m \u001B[31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\r\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m803.5/803.5 kB\u001B[0m \u001B[31m20.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n\u001B[?25hDownloading orjson-3.11.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (136 kB)\nDownloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\nInstalling collected packages: tqdm, regex, orjson, jsonpatch, jiter, tiktoken, requests-toolbelt, openai, langsmith, langchain-core, langchain-openai\nSuccessfully installed jiter-0.12.0 jsonpatch-1.33 langchain-core-1.0.5 langchain-openai-1.0.3 langsmith-0.4.43 openai-2.8.1 orjson-3.11.4 regex-2025.11.3 requests-toolbelt-1.0.0 tiktoken-0.12.0 tqdm-4.67.1\n\u001B[43mNote: you may need to restart the kernel using %restart_python or dbutils.library.restartPython() to use updated packages.\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install databricks-sdk[openai]>=0.35.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "376858ad-cab9-450f-b9ea-10c2ec932477",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1664eeaf-45e6-44d0-95d8-89d369325555",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A Mixture of Experts (MoE) model is a type of neural network architecture that combines the predictions of multiple expert models to produce a final output. The basic idea is to divide the input space into different regions, each handled by a specialized expert model. The experts are typically simple models, such as linear or small neural networks, that are trained to be proficient in a specific subset of the input data.\n\nThe MoE model consists of three main components:\n\n1. **Gating network**: This is a neural network that takes the input data and produces a set of weights or probabilities that determine the contribution of each expert to the final output. The gating network essentially decides which expert is most relevant for a given input.\n2. **Expert models**: These are the individual models that are responsible for making predictions in different regions of the input space. Each expert is trained on a subset of the data and is specialized to handle a specific type of input.\n3. **Output combination**: The outputs of the expert models are combined using the weights or probabilities produced by the gating network. This can be done using a weighted sum, a softmax function, or other combination methods.\n\nThe key advantages of MoE models are:\n\n* **Improved performance**: By allowing each expert to specialize in a specific\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from databricks.sdk import WorkspaceClient\n",
    "\n",
    "w = WorkspaceClient()\n",
    "openai_client = w.serving_endpoints.get_open_ai_client()\n",
    "\n",
    "response = openai_client.chat.completions.create(\n",
    "    model=\"databricks-meta-llama-3-3-70b-instruct\",\n",
    "    messages=[\n",
    "      {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"You are a helpful assistant.\"\n",
    "      },\n",
    "      {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"What is a mixture of experts model?\",\n",
    "      }\n",
    "    ],\n",
    "    max_tokens=256\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "32b7c112-92ae-4c18-b8bb-00b5a12348d5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "\n",
    "os.environ[\"YOUR_DATABRICKS_TOKEN\"] = \"dapi1123999e2fd1ea9c51255f99e8d495d3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ac5cd3ee-7756-48d9-8746-eb9fcbd5efac",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I don't have the ability to check current weather conditions or forecasts for Tokyo or any other location. To get accurate weather information for Tokyo, you could check a weather website like Weather.com or AccuWeather, use a weather app on your device, or search for \"Tokyo weather\" on a search engine.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import os\n",
    "import json\n",
    "from openai import OpenAI\n",
    "\n",
    "current_workspace = f'https://{spark.conf.get(\"spark.databricks.workspaceUrl\")}'\n",
    "\n",
    "DATABRICKS_TOKEN = os.environ.get('YOUR_DATABRICKS_TOKEN')\n",
    "DATABRICKS_BASE_URL = f'{current_workspace}/serving-endpoints'\n",
    "\n",
    "client = OpenAI(\n",
    "  api_key=DATABRICKS_TOKEN,\n",
    "  base_url=DATABRICKS_BASE_URL\n",
    "  )\n",
    "\n",
    "messages = [{\"role\": \"user\", \"content\": \"What is the weather in Tokyo?\"}]\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"databricks-claude-3-7-sonnet\",\n",
    "    messages=messages,\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4cded9da-48dd-4b9f-ab7c-1cbeed3bdcb5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mlflow\n  Downloading mlflow-3.6.0-py3-none-any.whl.metadata (31 kB)\nCollecting mlflow-skinny==3.6.0 (from mlflow)\n  Downloading mlflow_skinny-3.6.0-py3-none-any.whl.metadata (31 kB)\nCollecting mlflow-tracing==3.6.0 (from mlflow)\n  Downloading mlflow_tracing-3.6.0-py3-none-any.whl.metadata (19 kB)\nCollecting Flask-CORS<7 (from mlflow)\n  Downloading flask_cors-6.0.1-py3-none-any.whl.metadata (5.3 kB)\nCollecting Flask<4 (from mlflow)\n  Downloading flask-3.1.2-py3-none-any.whl.metadata (3.2 kB)\nCollecting alembic!=1.10.0,<2 (from mlflow)\n  Downloading alembic-1.17.2-py3-none-any.whl.metadata (7.2 kB)\nRequirement already satisfied: cryptography<47,>=43.0.0 in /databricks/python3/lib/python3.12/site-packages (from mlflow) (43.0.3)\nCollecting docker<8,>=4.0.0 (from mlflow)\n  Downloading docker-7.1.0-py3-none-any.whl.metadata (3.8 kB)\nCollecting graphene<4 (from mlflow)\n  Downloading graphene-3.4.3-py2.py3-none-any.whl.metadata (6.9 kB)\nCollecting gunicorn<24 (from mlflow)\n  Downloading gunicorn-23.0.0-py3-none-any.whl.metadata (4.4 kB)\nCollecting huey<3,>=2.5.0 (from mlflow)\n  Downloading huey-2.5.4-py3-none-any.whl.metadata (4.6 kB)\nRequirement already satisfied: matplotlib<4 in /databricks/python3/lib/python3.12/site-packages (from mlflow) (3.10.0)\nRequirement already satisfied: numpy<3 in /databricks/python3/lib/python3.12/site-packages (from mlflow) (2.1.3)\nRequirement already satisfied: pandas<3 in /databricks/python3/lib/python3.12/site-packages (from mlflow) (2.2.3)\nRequirement already satisfied: pyarrow<23,>=4.0.0 in /databricks/python3/lib/python3.12/site-packages (from mlflow) (19.0.1)\nRequirement already satisfied: scikit-learn<2 in /databricks/python3/lib/python3.12/site-packages (from mlflow) (1.6.1)\nRequirement already satisfied: scipy<2 in /databricks/python3/lib/python3.12/site-packages (from mlflow) (1.15.1)\nCollecting sqlalchemy<3,>=1.4.0 (from mlflow)\n  Downloading sqlalchemy-2.0.44-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.5 kB)\nRequirement already satisfied: cachetools<7,>=5.0.0 in /databricks/python3/lib/python3.12/site-packages (from mlflow-skinny==3.6.0->mlflow) (5.5.1)\nRequirement already satisfied: click<9,>=7.0 in /databricks/python3/lib/python3.12/site-packages (from mlflow-skinny==3.6.0->mlflow) (8.1.7)\nRequirement already satisfied: cloudpickle<4 in /databricks/python3/lib/python3.12/site-packages (from mlflow-skinny==3.6.0->mlflow) (3.0.0)\nRequirement already satisfied: databricks-sdk<1,>=0.20.0 in /databricks/python3/lib/python3.12/site-packages (from mlflow-skinny==3.6.0->mlflow) (0.49.0)\nRequirement already satisfied: fastapi<1 in /databricks/python3/lib/python3.12/site-packages (from mlflow-skinny==3.6.0->mlflow) (0.115.12)\nRequirement already satisfied: gitpython<4,>=3.1.9 in /databricks/python3/lib/python3.12/site-packages (from mlflow-skinny==3.6.0->mlflow) (3.1.43)\nRequirement already satisfied: importlib_metadata!=4.7.0,<9,>=3.7.0 in /databricks/python3/lib/python3.12/site-packages (from mlflow-skinny==3.6.0->mlflow) (6.6.0)\nRequirement already satisfied: opentelemetry-api<3,>=1.9.0 in /databricks/python3/lib/python3.12/site-packages (from mlflow-skinny==3.6.0->mlflow) (1.32.1)\nCollecting opentelemetry-proto<3,>=1.9.0 (from mlflow-skinny==3.6.0->mlflow)\n  Downloading opentelemetry_proto-1.38.0-py3-none-any.whl.metadata (2.3 kB)\nRequirement already satisfied: opentelemetry-sdk<3,>=1.9.0 in /databricks/python3/lib/python3.12/site-packages (from mlflow-skinny==3.6.0->mlflow) (1.32.1)\nRequirement already satisfied: packaging<26 in /databricks/python3/lib/python3.12/site-packages (from mlflow-skinny==3.6.0->mlflow) (24.1)\nRequirement already satisfied: protobuf<7,>=3.12.0 in /databricks/python3/lib/python3.12/site-packages (from mlflow-skinny==3.6.0->mlflow) (5.29.4)\nRequirement already satisfied: pydantic<3,>=2.0.0 in /databricks/python3/lib/python3.12/site-packages (from mlflow-skinny==3.6.0->mlflow) (2.10.6)\nCollecting python-dotenv<2,>=0.19.0 (from mlflow-skinny==3.6.0->mlflow)\n  Downloading python_dotenv-1.2.1-py3-none-any.whl.metadata (25 kB)\nRequirement already satisfied: pyyaml<7,>=5.1 in /databricks/python3/lib/python3.12/site-packages (from mlflow-skinny==3.6.0->mlflow) (6.0.2)\nRequirement already satisfied: requests<3,>=2.17.3 in /databricks/python3/lib/python3.12/site-packages (from mlflow-skinny==3.6.0->mlflow) (2.32.3)\nRequirement already satisfied: sqlparse<1,>=0.4.0 in /databricks/python3/lib/python3.12/site-packages (from mlflow-skinny==3.6.0->mlflow) (0.5.3)\nRequirement already satisfied: typing-extensions<5,>=4.0.0 in /databricks/python3/lib/python3.12/site-packages (from mlflow-skinny==3.6.0->mlflow) (4.12.2)\nRequirement already satisfied: uvicorn<1 in /databricks/python3/lib/python3.12/site-packages (from mlflow-skinny==3.6.0->mlflow) (0.34.2)\nCollecting Mako (from alembic!=1.10.0,<2->mlflow)\n  Downloading mako-1.3.10-py3-none-any.whl.metadata (2.9 kB)\nRequirement already satisfied: cffi>=1.12 in /databricks/python3/lib/python3.12/site-packages (from cryptography<47,>=43.0.0->mlflow) (1.17.1)\nRequirement already satisfied: urllib3>=1.26.0 in /databricks/python3/lib/python3.12/site-packages (from docker<8,>=4.0.0->mlflow) (2.3.0)\nCollecting blinker>=1.9.0 (from Flask<4->mlflow)\n  Downloading blinker-1.9.0-py3-none-any.whl.metadata (1.6 kB)\nCollecting itsdangerous>=2.2.0 (from Flask<4->mlflow)\n  Downloading itsdangerous-2.2.0-py3-none-any.whl.metadata (1.9 kB)\nRequirement already satisfied: jinja2>=3.1.2 in /databricks/python3/lib/python3.12/site-packages (from Flask<4->mlflow) (3.1.5)\nRequirement already satisfied: markupsafe>=2.1.1 in /databricks/python3/lib/python3.12/site-packages (from Flask<4->mlflow) (3.0.2)\nCollecting werkzeug>=3.1.0 (from Flask<4->mlflow)\n  Downloading werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\nCollecting graphql-core<3.3,>=3.1 (from graphene<4->mlflow)\n  Downloading graphql_core-3.2.7-py3-none-any.whl.metadata (11 kB)\nCollecting graphql-relay<3.3,>=3.1 (from graphene<4->mlflow)\n  Downloading graphql_relay-3.2.0-py3-none-any.whl.metadata (12 kB)\nRequirement already satisfied: python-dateutil<3,>=2.7.0 in /databricks/python3/lib/python3.12/site-packages (from graphene<4->mlflow) (2.9.0.post0)\nRequirement already satisfied: contourpy>=1.0.1 in /databricks/python3/lib/python3.12/site-packages (from matplotlib<4->mlflow) (1.3.1)\nRequirement already satisfied: cycler>=0.10 in /databricks/python3/lib/python3.12/site-packages (from matplotlib<4->mlflow) (0.11.0)\nRequirement already satisfied: fonttools>=4.22.0 in /databricks/python3/lib/python3.12/site-packages (from matplotlib<4->mlflow) (4.55.3)\nRequirement already satisfied: kiwisolver>=1.3.1 in /databricks/python3/lib/python3.12/site-packages (from matplotlib<4->mlflow) (1.4.8)\nRequirement already satisfied: pillow>=8 in /databricks/python3/lib/python3.12/site-packages (from matplotlib<4->mlflow) (11.1.0)\nRequirement already satisfied: pyparsing>=2.3.1 in /databricks/python3/lib/python3.12/site-packages (from matplotlib<4->mlflow) (3.2.0)\nRequirement already satisfied: pytz>=2020.1 in /databricks/python3/lib/python3.12/site-packages (from pandas<3->mlflow) (2024.1)\nRequirement already satisfied: tzdata>=2022.7 in /databricks/python3/lib/python3.12/site-packages (from pandas<3->mlflow) (2024.1)\nRequirement already satisfied: joblib>=1.2.0 in /databricks/python3/lib/python3.12/site-packages (from scikit-learn<2->mlflow) (1.4.2)\nRequirement already satisfied: threadpoolctl>=3.1.0 in /databricks/python3/lib/python3.12/site-packages (from scikit-learn<2->mlflow) (3.5.0)\nCollecting greenlet>=1 (from sqlalchemy<3,>=1.4.0->mlflow)\n  Downloading greenlet-3.2.4-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (4.1 kB)\nRequirement already satisfied: pycparser in /databricks/python3/lib/python3.12/site-packages (from cffi>=1.12->cryptography<47,>=43.0.0->mlflow) (2.21)\nRequirement already satisfied: google-auth~=2.0 in /databricks/python3/lib/python3.12/site-packages (from databricks-sdk<1,>=0.20.0->mlflow-skinny==3.6.0->mlflow) (2.40.0)\nRequirement already satisfied: starlette<0.47.0,>=0.40.0 in /databricks/python3/lib/python3.12/site-packages (from fastapi<1->mlflow-skinny==3.6.0->mlflow) (0.46.2)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /databricks/python3/lib/python3.12/site-packages (from gitpython<4,>=3.1.9->mlflow-skinny==3.6.0->mlflow) (4.0.11)\nRequirement already satisfied: zipp>=0.5 in /databricks/python3/lib/python3.12/site-packages (from importlib_metadata!=4.7.0,<9,>=3.7.0->mlflow-skinny==3.6.0->mlflow) (3.21.0)\nRequirement already satisfied: deprecated>=1.2.6 in /databricks/python3/lib/python3.12/site-packages (from opentelemetry-api<3,>=1.9.0->mlflow-skinny==3.6.0->mlflow) (1.2.13)\nRequirement already satisfied: opentelemetry-semantic-conventions==0.53b1 in /databricks/python3/lib/python3.12/site-packages (from opentelemetry-sdk<3,>=1.9.0->mlflow-skinny==3.6.0->mlflow) (0.53b1)\nRequirement already satisfied: annotated-types>=0.6.0 in /databricks/python3/lib/python3.12/site-packages (from pydantic<3,>=2.0.0->mlflow-skinny==3.6.0->mlflow) (0.7.0)\nRequirement already satisfied: pydantic-core==2.27.2 in /databricks/python3/lib/python3.12/site-packages (from pydantic<3,>=2.0.0->mlflow-skinny==3.6.0->mlflow) (2.27.2)\nRequirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil<3,>=2.7.0->graphene<4->mlflow) (1.16.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /databricks/python3/lib/python3.12/site-packages (from requests<3,>=2.17.3->mlflow-skinny==3.6.0->mlflow) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /databricks/python3/lib/python3.12/site-packages (from requests<3,>=2.17.3->mlflow-skinny==3.6.0->mlflow) (3.7)\nRequirement already satisfied: certifi>=2017.4.17 in /databricks/python3/lib/python3.12/site-packages (from requests<3,>=2.17.3->mlflow-skinny==3.6.0->mlflow) (2025.1.31)\nRequirement already satisfied: h11>=0.8 in /databricks/python3/lib/python3.12/site-packages (from uvicorn<1->mlflow-skinny==3.6.0->mlflow) (0.14.0)\nRequirement already satisfied: wrapt<2,>=1.10 in /databricks/python3/lib/python3.12/site-packages (from deprecated>=1.2.6->opentelemetry-api<3,>=1.9.0->mlflow-skinny==3.6.0->mlflow) (1.17.0)\nRequirement already satisfied: smmap<6,>=3.0.1 in /databricks/python3/lib/python3.12/site-packages (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow-skinny==3.6.0->mlflow) (5.0.0)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /databricks/python3/lib/python3.12/site-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.6.0->mlflow) (0.2.8)\nRequirement already satisfied: rsa<5,>=3.1.4 in /databricks/python3/lib/python3.12/site-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.6.0->mlflow) (4.9.1)\nRequirement already satisfied: anyio<5,>=3.6.2 in /databricks/python3/lib/python3.12/site-packages (from starlette<0.47.0,>=0.40.0->fastapi<1->mlflow-skinny==3.6.0->mlflow) (4.6.2)\nRequirement already satisfied: sniffio>=1.1 in /databricks/python3/lib/python3.12/site-packages (from anyio<5,>=3.6.2->starlette<0.47.0,>=0.40.0->fastapi<1->mlflow-skinny==3.6.0->mlflow) (1.3.0)\nRequirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /databricks/python3/lib/python3.12/site-packages (from pyasn1-modules>=0.2.1->google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.6.0->mlflow) (0.4.8)\nDownloading mlflow-3.6.0-py3-none-any.whl (8.9 MB)\n\u001B[?25l   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m0.0/8.9 MB\u001B[0m \u001B[31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\r\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m8.9/8.9 MB\u001B[0m \u001B[31m129.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n\u001B[?25hDownloading mlflow_skinny-3.6.0-py3-none-any.whl (2.4 MB)\n\u001B[?25l   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m0.0/2.4 MB\u001B[0m \u001B[31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\r\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m2.4/2.4 MB\u001B[0m \u001B[31m120.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n\u001B[?25hDownloading mlflow_tracing-3.6.0-py3-none-any.whl (1.3 MB)\n\u001B[?25l   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m0.0/1.3 MB\u001B[0m \u001B[31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\r\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m1.3/1.3 MB\u001B[0m \u001B[31m68.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n\u001B[?25hDownloading alembic-1.17.2-py3-none-any.whl (248 kB)\nDownloading docker-7.1.0-py3-none-any.whl (147 kB)\nDownloading flask-3.1.2-py3-none-any.whl (103 kB)\nDownloading flask_cors-6.0.1-py3-none-any.whl (13 kB)\nDownloading graphene-3.4.3-py2.py3-none-any.whl (114 kB)\nDownloading gunicorn-23.0.0-py3-none-any.whl (85 kB)\nDownloading huey-2.5.4-py3-none-any.whl (76 kB)\nDownloading sqlalchemy-2.0.44-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n\u001B[?25l   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m0.0/3.3 MB\u001B[0m \u001B[31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\r\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m3.3/3.3 MB\u001B[0m \u001B[31m138.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n\u001B[?25hDownloading blinker-1.9.0-py3-none-any.whl (8.5 kB)\nDownloading graphql_core-3.2.7-py3-none-any.whl (207 kB)\nDownloading graphql_relay-3.2.0-py3-none-any.whl (16 kB)\nDownloading greenlet-3.2.4-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (607 kB)\n\u001B[?25l   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m0.0/607.6 kB\u001B[0m \u001B[31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\r\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m607.6/607.6 kB\u001B[0m \u001B[31m27.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n\u001B[?25hDownloading itsdangerous-2.2.0-py3-none-any.whl (16 kB)\nDownloading opentelemetry_proto-1.38.0-py3-none-any.whl (72 kB)\nDownloading python_dotenv-1.2.1-py3-none-any.whl (21 kB)\nDownloading werkzeug-3.1.3-py3-none-any.whl (224 kB)\nDownloading mako-1.3.10-py3-none-any.whl (78 kB)\nInstalling collected packages: huey, werkzeug, python-dotenv, opentelemetry-proto, Mako, itsdangerous, gunicorn, greenlet, graphql-core, blinker, sqlalchemy, graphql-relay, Flask, docker, graphene, Flask-CORS, alembic, mlflow-tracing, mlflow-skinny, mlflow\n  Attempting uninstall: blinker\n    Found existing installation: blinker 1.7.0\n    Not uninstalling blinker at /usr/lib/python3/dist-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-818a014d-a35f-4d70-a605-8468f905846f\n    Can't uninstall 'blinker'. No files were found to uninstall.\n  Attempting uninstall: mlflow-skinny\n    Found existing installation: mlflow-skinny 2.22.0\n    Not uninstalling mlflow-skinny at /databricks/python3/lib/python3.12/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-818a014d-a35f-4d70-a605-8468f905846f\n    Can't uninstall 'mlflow-skinny'. No files were found to uninstall.\nSuccessfully installed Flask-3.1.2 Flask-CORS-6.0.1 Mako-1.3.10 alembic-1.17.2 blinker-1.9.0 docker-7.1.0 graphene-3.4.3 graphql-core-3.2.7 graphql-relay-3.2.0 greenlet-3.2.4 gunicorn-23.0.0 huey-2.5.4 itsdangerous-2.2.0 mlflow-3.6.0 mlflow-skinny-3.6.0 mlflow-tracing-3.6.0 opentelemetry-proto-1.38.0 python-dotenv-1.2.1 sqlalchemy-2.0.44 werkzeug-3.1.3\n\u001B[43mNote: you may need to restart the kernel using %restart_python or dbutils.library.restartPython() to use updated packages.\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "%pip install -U mlflow\n",
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "685f1a24-4607-43c4-baa2-b2d8c9fe1492",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "mlflow.openai.autolog()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6832faff-0e89-4736-945c-57f49fb25a9f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n  {\n    \"id\": \"toolu_bdrk_01RqrgXDu94UXSGBTSX7Brnh\",\n    \"function\": {\n      \"arguments\": \"{\\\"location\\\":\\\"Tokyo\\\",\\\"unit\\\":\\\"celsius\\\"}\",\n      \"name\": \"get_current_weather\"\n    },\n    \"type\": \"function\"\n  }\n]\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/databricks.mlflow.trace": "{\"trace_id\": \"tr-81b0a7888526a19482c081cef3033eb4\", \"sql_warehouse_id\": null}",
      "text/plain": [
       "Trace(trace_id=tr-81b0a7888526a19482c081cef3033eb4)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import json\n",
    "from openai import OpenAI\n",
    "\n",
    "current_workspace = f'https://{spark.conf.get(\"spark.databricks.workspaceUrl\")}'\n",
    "os.environ[\"YOUR_DATABRICKS_TOKEN\"] = \"dapi1123999e2fd1ea9c51255f99e8d495d3\"\n",
    "DATABRICKS_TOKEN = os.environ.get('YOUR_DATABRICKS_TOKEN')\n",
    "DATABRICKS_BASE_URL = f'{current_workspace}/serving-endpoints'\n",
    "\n",
    "client = OpenAI(\n",
    "  api_key=DATABRICKS_TOKEN,\n",
    "  base_url=DATABRICKS_BASE_URL\n",
    "  )\n",
    "\n",
    "tools = [\n",
    "  {\n",
    "    \"type\": \"function\",\n",
    "    \"function\": {\n",
    "      \"name\": \"get_current_weather\",\n",
    "      \"description\": \"Get the current weather in a given location\",\n",
    "      \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "          \"location\": {\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"The city and state, e.g. San Francisco, CA\"\n",
    "          },\n",
    "          \"unit\": {\n",
    "            \"type\": \"string\",\n",
    "            \"enum\": [\n",
    "              \"celsius\",\n",
    "              \"fahrenheit\"\n",
    "            ]\n",
    "          }\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "]\n",
    "\n",
    "messages = [{\"role\": \"user\", \"content\": \"What is the weather in Tokyo in celsius?\"}]\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"databricks-claude-3-7-sonnet\",\n",
    "    messages=messages,\n",
    "    tools=tools,\n",
    "    tool_choice=\"auto\",\n",
    ")\n",
    "\n",
    "print(json.dumps(response.choices[0].message.model_dump()['tool_calls'], indent=2))"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Using Databricks Notebooks for GenAI",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}